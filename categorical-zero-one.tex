\documentclass[11pt]{article}
\usepackage{eigilscmds}
\usepackage{tikzit}
\usepackage{geometry}
\usepackage{enumerate}
\input{comonoids.tikzdefs}
\input{comonoids.tikzstyles}

% draft packages
\usepackage{todonotes}
\usepackage{showkeys}

\author{Tobias Fritz and Eigil Fjeldgren Rischel}
\title{The zero--one laws of Kolmogorov and Hewitt--Savage in categorical probability}
\date{\today}

\renewcommand{\sf}{\mathsf}
\DeclareMathOperator{\del}{del}
\begin{document}
\maketitle

\begin{abstract}
	We state and prove the zero--one laws of Kolmogorov and Hewitt--Savage within the setting of \emph{Markov categories}, a category-theoretic approach to the foundations of probability and statistics. This gives general versions of these results which can be instantiated not only in measure-theoretic probability, where they specialize to the standard ones, but also in other contexts such as categories of closed relations between topological spaces, 
	\improve{T: this abstract states what we can hopefully achieve. To be adjusted}
\end{abstract}

\tableofcontents

\section{Introduction}

This is a treatment of the zero--one laws of Kolmogorov and of Hewitt--Savage in the setting of Markov categories.

\paragraph*{Notation.} 

For monoidal categories, we make frequent use of string diagram notation. We omit object labels whenever these are obvious from the context.

In \Cref{infprod_semicartesian}, $\cC$ denotes a semicartesian monoidal category. In \Cref{infprod_markov} and after, $\cC$ denotes a Markov category in the sense of \Cref{markov_cat}. $J$ is a set used for indexing products of objects; the definitions and results of this paper are nontrivial only when $J$ is infinite. $F$ denotes either an arbitrary finite set or more concretely a finite subset of $J$.

\section{Background on Markov categories}

A monoidal category $\cC$ is \emph{semicartesian} if the monoidal unit $I \in \cC$ is terminal. Equivalently, it is a monoidal category equipped with morphisms
\[
	X \otimes Y \longrightarrow X, \qquad X \otimes Y \longrightarrow Y,
\]
which are natural in $X$ and $Y$ and coincide with the monoidal structure isomorphisms whenever $X = I$ or $Y = I$. Here are the main examples that we will be considering.

\begin{example}
	$\FinStoch$ is the category of finite sets with \emph{stochastic maps}, where a stochastic map $f : X \to Y$ is a matrix $(f_{xy})_{x \in X,y \in Y}$ of nonnegative real numbers such that $\sum_y f_{xy} = 1$ for every $x$. Stochastic maps compose by matrix multiplication, which in this context is also known as the \emph{Chapman--Kolmogorov equation}. We consider $\FinStoch$ as a monoidal category with respect to the cartesian product of sets on objects, and as one would expect the Kronecker product of stochastic maps on morphisms.
\end{example}

\begin{example}
	Let $\CRing_+$ be the category of commutative rings with maps which are merely additive and unit-preserving, considered as a monoidal category in the obvious way with respect to the tensor product of rings. Then since $\CRing_+$ has the monoidal unit $\Z$ as its initial object, we can conclude that $\CRing_+\op$ is semicartesian monoidal.
\end{example}

\begin{example}
	$\Stoch$ is the category of measurable spaces $(X,\Sigma_X)$ as objects and Markov kernels as morphisms. We sketch the definition here and refer to~\cite[Section~4]{markov_cats} and references therein for the details. A \emph{Markov kernel} $(X,\Sigma_X) \to (Y,\Sigma_Y)$ is a function
	\[
		f \: : \: \Sigma_Y \times X \longrightarrow [0,1], \quad (S,x) \longmapsto f(S|x)
	\]
	assigning to every $x \in X$ a probability measure $f(-|x) : \Sigma_Y \to [0,1]$ in such a way that for every $S \in \Sigma_Y$, the function $x \mapsto f(S|x)$ is measurable. Intuitively, $f$ assigns to every $x \in X$ a random element of $Y$. Composition is again defined by a variant of the Chapman--Kolmogorov equation, and the monoidal structure is defined in terms of the usual product of measurable spaces.
\end{example}

In the graphical calculus, the unique morphism $X \to I$ for an object $X \in \cC$ is denoted by
\[
	\tikzfig{terminal}
\]
The projection maps $X \otimes Y \to X$ and $X \otimes Y \to Y$ are correspondingly written as
\[
	\tikzfig{marginals}
\]

Our goal is to use semicartesian monoidal categories such as the above in order to develop aspects of probability theory in categorical terms. As it turns out, doing so requires a bit more structure, in a form which has been axiomatized in the notion of \emph{Markov category} \cite[Definition~2.1]{markov_cats}. 

\begin{definition}
	A Markov category $\cC$ is a semicartesian monoidal category \ldots
	\label{markov_cat}
\end{definition}

A closely related definition was also used in earlier work of Golubtsov~\cite{golubtsov}, who had proposed a closely related definition, and Cho and Jacobs~\cite{cho_jacobs}, where an equivalent definition was used under the term \emph{affine CD-category}.

\todo[inline]{to be written}

\section{Infinite tensor products in semicartesian monoidal categories}
\label{infprod_semicartesian}

\todo[inline]{Let's also simplify notation by writing $X_J$ and $X_F$ instead of writing $\bigotimes$ every time. This is quite standard}

Suppose $\cC$ is a semicartesian monoidal category. In our 

In order to make sense of infinite families of random variables within $\cC$,
we will want to have a notion of infinite tensor product in $\cC$. By Kolmogorov's extension theorem, the joint distribution of infinitely many random variables is uniquely determined by the family of distributions of all finite subsets of these variables. This motivates a general definition of the infinite tensor product of a family of objects $(X_i)_{i \in J}$, based on the observation that if $F \subseteq F' \subseteq J$ are two finite subset, then the fact that $\cC$ is semicartesian monoidal gives us morphisms
\[
	\bigotimes_{i \in F'} X_i \longrightarrow \bigotimes_{i \in F} X_i
\]
to be interpreted as \emph{marginalization}. Via these maps, the finite tensor products $\bigotimes_{i \in F} X_i$ make up a cofiltered diagram in the form of a functor from the poset of finite subsets of $J$, ordered by reverse inclusion, to $\cC$.

\begin{definition}
    Let $(X_i)_{i \in J}$ be a family of objects in $\cC$.
    Then the \emph{infinite tensor product} $\bigotimes_{i \in J} X_i$ is the limit of the diagram \[F \longmapsto \bigotimes_{i \in F} X_i,\]
    indexed by the poset of finite subsets $F \subset J$ ordered by reverse inclusion, if this limit exists.
\end{definition}

We will refer to the structure maps $\pi_F : \bigotimes_{i\in J} X_i \to \bigotimes_{i\in F} X_i$ as \emph{finite marginalizations}, and also write $\pi_j$ as shorthand for $\pi_{\{j\}}$.

The dual definition of infinite tensor products of algebraic structures as \emph{filtered colimits} of finite tensor products is well-known in the literature, e.g.~in the case of C*-algebras~\cite[p.~315]{blackadar}. Intuitively, our definition matches up with these under the categorical duality of algebra and geometry, where our definition is on the geometrical side of the duality.

\begin{remark}
	If $J$ is finite, the infinite tensor product exists and coincides with the standard tensor product $\bigotimes_{i \in J} X_i$.
\end{remark}

Of course, in a general Markov category the above cofiltered limit need not exist for infinite $J$, in which case the infinite tensor product does not exist either (as in \Cref{infprods_finstoch}).

\begin{lemma}
    Let $J,J'$ be possibly infinite sets, and $\{X_i\}_{i\in J}, \{Y_i\}_{i\in J'}$ two families of objects in $\cC$, so that both have infinite tensor products with Kolmogorov extension.
    Let $\{Z_i\}_{i\in J \sqcup J'}$ be a family of objects indexed by the disjoint union, where $Z_i = X_i$ for $i\in J$, $Z_i = Y_i$ for $i \in J'$,
    and suppose $\{Z_i\}$ admits an infinite tensor product with Kolmogorov extension, too.
    Consider the family of maps
    \[\rho_F: \bigotimes_{i\in J}X_i \tensor \bigotimes_{i\in J'} Y_i \labelto{\pi_{F \cap J} \tensor \pi_{F \cap J'}} \bigotimes_{i \in F \cap J}X_i \tensor \bigotimes_{i\in F \cap J'}Y_i\]
    indexed by finite subsets $F \subset J \sqcup J'$ of the disjoint union.
    The induced map
    \[\bigotimes_{i\in J}X_i \tensor \bigotimes_{i\in J'} Y_i \to \bigotimes_{i \in J \sqcup J'} Z_i\]
    is a deterministic isomorphism.
\end{lemma}
\begin{proof}
    It is clear that the $\rho_F$ are deterministic, and that they form a limit diagram in $\cC_{\rm det}$.
    Hence the induced map into the actual limit in $\cC_{\rm det}$ is an isomorphism.
\end{proof}

\section{Infinite tensor products in Markov categories}
\label{infprod_markov}

If a Markov category $\cC$ has infinite tensor products, then one should expect a suitable compatibility condition between these infinite tensor products and the comonoid structures on the objects to be satisfied. In the following string diagrams, we draw the object associated to an infinite tensor product as a double wire.

\begin{definition}
    \label{defn_kolmogorov_ext}
    Let $\cC$ be a Markov category, let $\{X_i\}_{i\in J}$ be an infinite family of objects, and let $\bigotimes_i X_i$ be an infinite tensor product.
    We say this product \emph{satisfies Kolmogorov extension} if the following two conditions hold:
    \begin{enumerate}[(1)]
        \item The finite marginals \[\pi_F: \bigotimes_{i\in J} X_i \to \bigotimes_{i \in F} X_i\] are deterministic
        \item These maps exhibit $\bigotimes_{i\in J} X_i$ as the cofiltered limit of the diagram $F \mapsto \bigotimes_{i \in F} X_i$ \emph{in $\cC_{\rm det}$}.
    \end{enumerate}
\end{definition}

\todo[inline]{Perhaps we could change the terminology to ``Kolmogorov product''. I'll tentatively use this in the following}

\begin{remark}
    Since the (finite) tensor product is the product in $\cC_{\rm det}$, condition (2) is equivalent to the statement that the marginals
    \[\pi_j: \bigotimes_i X_i \to X_j\]
    exhibit $\bigotimes_i X_i$ as the product of the $X_j$ in $\cC_{\rm det}$,
    since in any category, \[\lim_{F \subset J} \prod_{i \in F}X_i \cong \prod_{i \in J}X_i\]
\end{remark}

\begin{remark}
    Condition (2) is also equivalent to the statement that, given a compatible family of deterministic maps $a_F: A \to \bigotimes_{i \in F} X_i$, the induced map $a: A \to \bigotimes_i X_i$ is deterministic.
\end{remark}


This determines the comonoid structure uniquely: $\mathsf{copy}_{\bigotimes_i X_i}$ has to be the diagonal map in $\cC_{\rm det}$,
and this condition determines $\bigotimes_i X_i$ up to \emph{deterministic} isomorphism.

\begin{remark}
    Isomorphic objects in a Markov category can have non-isomorphic comonoid structures~\cite[Remark~10.9]{markov_cats}.
    Therefore the condition of \Cref{defn_kolmogorov_ext} generally depends on the particular \emph{choice} of the infinite tensor product, rather than only on the mere existence of infinite tensor products in the underlying semicartesian monoidal category.
\end{remark}


To actually use this idea to reproduce the usual Kolmogorov zero-one law, we need to do a bit of work:

\begin{example}
Let $\{(X_i,\Sigma_i)\}_{i\in J}$ be a set of measurable spaces in $\sf{Stoch}$.
Then consider their product $X = \prod_i X_i$ with the $\sigma$-algebra generated by the projections $\pi_i: X \to X_i$, which we denote $\Sigma$.
Let us write in general $X_F = \prod_{i\in F}X_F$, $\Sigma_F$ for the corresponding $\sigma$-algebra, and $\pi_F: X \to X_F$ for the projection.

Let $\{p_F: A \times \Sigma_F \to [0,1]\}_{F \subset J}$ be a collection of Markov kernels $A \to \prod_{i \in F}X_i$ for each $F$, compatible in the suitable sense.
Consider a point $a \in A$ and a generator $\pi_F\inv(B)$ for $\Sigma$, where $B \in \Sigma_F$.
Then we define $p(a,\pi_F\inv(B)) = p_F(a,B)$.
Note that the collection of such $\pi_F\inv(B)$ is a ring of sets on $X$ which generates $\Sigma$ - hence by Caratheodory extension, there is a unique probability measure
$p(a,-)$ on $X$ extending it. This is how we define $p(a,A)$ for general subsets $A \subset X$.

Now consider the class of subsets $A \in \Sigma$ such that $p(-,A):A \to X$ is measurable.
This class is a $\sigma$-algebra, which contains $\pi_F\inv(B)$, since $p(-,\pi_F\inv(B)) = p_F(-,B)$, which is measurable by assumption.
Since these generate $\Sigma$, the map is always measurable.
Hence $p$ is a Markov kernel.

This argument also shows that this Markov kernel is determined uniquely by the fact that $p(a,\pi_F\inv(B)) = p_F(a,B) = \pi_F \circ p$.
This proves that $(X,\Sigma)$ is the limit of $(X_F,\Sigma_F)$, so that it is the tensor product $\bigotimes_{i\in J} X_i$.
It is simple to verify that it also has Kolmogorov extension, using e.g. \cite[Example~10.4]{markov_cats}
\end{example}

\begin{example}
	\label{infprods_finstoch}
	$\sf{FinStoch}$ does not have infinite tensor products.
\end{example}
\todo[inline]{Add an example where $\cC_{\rm det}$ has infinite products, but $\cC$ lacks infinite tensor products? Like sets and multivalued functions?}

From this point, the term \emph{infinite tensor product} will refer always to an infinite tensor product with Kolmogorov extension.

This notion of infinite tensor product describes a notion of infinite collection of random variable where all dependence must be witnessed on some finite subset of the variables.

We can codify this in the following definition
\begin{definition}
    Let $p: A \to \bigotimes_{i\in J}X_i$ be a map in $\cC$.
    We say it exhibits the independence of $\{X_i\}$ given $A$ if each finite marginalization $A \to \bigotimes_{i \in F}X_i$ exhibits the independence of $\{X_i\}_{i \in F}$ given $A$.
\end{definition}

\section{Theorem}
\begin{theorem}
    \label{thm:kolmog}
    Suppose we are given $p: A \to T \tensor \bigotimes_{i \in J} X_i$ satisfying the following conditions:
    \begin{enumerate}
        \item $T$ is a deterministic function of $\bigotimes_{i \in J} X_i$.
        \item For each finite subset $F \subset J$, the marginal $A \to T \tensor \bigotimes_{i \in F}X_i$ displays the independence of $T$ and $\bigotimes_{i \in F} X_i$.
    \end{enumerate}
    Then the marginal $A \to T$ is deterministic as well.
\end{theorem}

This theorem is a consequence of two lemmas.
\begin{lemma}[The infinite independence lemma]
    Suppose $p: A \to \bigotimes X_i$ exhibits the independence of $\{X_i\}$.
    Then for each $j$, the map $A \to X_j \tensor \bigotimes_{i \neq j}X_i$ exhibits the independence $X_j \bot \tensor_{i\neq j} X_i \mid \mid A$.
\end{lemma}
\begin{proof}[Sketch of proof]
    To prove this, we must compare two maps $A \to X_j \tensor \bigotimes_{i\neq j} X_i \cong \bigotimes_i X_i$.
    To show that these maps are equal, it suffices to show that all finite marginalizations of them are equal.
    But this is an immediate consequence of the assumption.
\end{proof}


\begin{lemma}[The determinism lemma]
    Suppose $p: A \to T \tensor X$ is such that $T$ is a deterministic function of $X$, and $p$ exhibits the independence $T \bot X \mid \mid A$.
    Then the marginal $A \to T$ is deterministic.
\end{lemma}
\begin{proof}
The proof is a string diagram chase:
First, the assumption that $T$ is a deterministic function of $X$ means precisely that we can find $f$ deterministic so that.

%\tikzfig{determinismlemma1}.

Now we can use the independence of $X$ and $T$, and the axioms, to rewrite this as

%\tikzfig{determinismlemma2}

Applying the map $1_T \tensor f$ to the second and fourth diagram now gives an equality

%\tikzfig{determinismlemma3}

Where we have also applied the determinism of $f$.
This is precisely the statement that $A \to T \tensor X \to X \labelto{f} T$ is deterministic.

Lastly, we use the equality 

%\tikzfig{determinismlemma4}

To see that the marginal $A \to T \tensor X \to T$ is deterministic as desired.

\end{proof}


\begin{proof}[Proof of the theorem]
    It's clear from the definition that $A \to T \tensor \bigotimes X_i$ exhibits the independence of $\{T, X_1, \dots\}$.
    By the infinite independence lemma, this means that it also exhibits the independence $T \bot \bigotimes X_i \mid \mid A$.
    Now the determinism lemma implies exactly what we want, that the marginal $A \to T$ is deterministic.
\end{proof}

\begin{corollary}[Kolmogorov zero to one law]
    Suppose $\Omega$ is a measure space with a probability measure $P$, $\{f_i: \Omega \to X_i\}$ is a collection of independent random variables,
    and $T \subset \Omega$ is a subset in the $\sigma$-algebra generated by the $f_i$, such that $1_T$ is independent of any finite subset of the $f_i$.
    Then $P(T)$ is $0$ or $1$.
\end{corollary}
\begin{proof}
    Consider the composite $I \labelto{P} \Omega \labelto{1_T, \{f_i\}} \{0,1\} \tensor \bigotimes_i X_i$.
    Then independence of the $f_i$ means precisely that this map exhibits the independence of $\{X_i\}$ given $I$ in the above sense.
    Moreover, $T(\omega)$ is determined by the values of $f_i(\omega)$, so $T$ factors as a map $\prod_i X_i \to \{0,1\}$, and
    this map is measurable.
    Hence we can apply the theorem, and conclude that the map $I \labelto{P} \Omega \labelto{T} \{0,1\}$ is deterministic - but this means it's just a constant map,
    which precisely means that $T$ is true or false with probability $1$.
\end{proof}

We can also prove a version of the Hewitt-Savage theorem
\begin{definition}
    Let $\alpha: J \to J$ be any map.
    Then it induces a map 
    \[\hat{\alpha}: \bigotimes_{i\in J}X_i \to \bigotimes_{i \in J}X_{\alpha(i)},\]
    which we may suggestively write as $(x_i)_{i\in J} \mapsto (x_{\alpha(i)})_{i\in J}$.
    
    It is clear that this map is always deterministic. Moreover, if $\alpha$ is a bijection, this map is an isomorphism.
\end{definition}

\begin{theorem}[Hewitt-Savage for Markov categories]
    \label{thm:hewsav}
    Let $\cC$ be a causal Markov category with infinite tensor products. Let $A \to \cC$ be a map in $\cC$, $J$ an infinite set, and let $f: \bigotimes_{i \in J}X \to T$ be a deterministic map.
    Suppose for each finite permutation $\sigma: J \to J$, we have $f \circ \hat{\sigma} = f$ - in other words, $f$ is independent of finite permutations of the inputs.
    Then the composite $A \to \tensor_J A \to \tensor_J X \to T$ is deterministic.
\end{theorem}
Again, we factor part of the proof into a lemma.
\begin{lemma}
    Let $\cC$ be a causal markov category, and let $f,g: B \to X$ be maps, $f$ deterministic.
    Let $p: A \to B$ be any map.
    Suppose the composites 
    \[A \to B \to B \tensor B \labelto{f \tensor g} X \tensor X\]
    and
    \[A \to B \to B \tensor B \labelto{f \tensor f} X \tensor X\]
    agree. Then $f = g$ $p$-almost everywhere.
\end{lemma}
\begin{proof}[Sketch of sketch of proof]
    Consider the map
    $A \labelto{p} B \to B \tensor B \labelto{f \tensor g} X \tensor X \labelto{copy_{X \tensor X}} X \tensor X \tensor X \tensor X$.
    Whether we marginalize on the first or second factor of $X$, we get equal morphisms, because we may replace the first part of this with
    $A \to B \labelto{f} B \to X \tensor X \tensor X \tensor X$ by using the assumptions and determinism.

    Then applying causality, with $f = p$, $g= (f \tensor g) \circ copy_B$, $h_1 = (del_X \tensor 1_X)$, $h_2  = (1_X \tensor del_X)$.
    Marginalizing the resulting (equal) diagrams, one of them is 
    \[A \to B \to B \tensor B \labelto{f, 1_B} B \tensor B,\]
    one of them is 
    \[A \to B \to B \tensor B \labelto{g,1_B} B \tensor B,\]
    and this is precisely what must hold for them to agree $p$-a.e.
\end{proof}

\begin{proof}[Proof of theorem]
    Consider the map 

    \[e: A \to \tensor_J A \labelto{\tensor p} (\tensor_J X) \to (\tensor_J X) \tensor (\tensor_J X) \to T \tensor (\tensor_J X)\]

    Denote by $e_\sigma$ the composite of $e$ with $1_T \tensor \hat{\sigma}$
    Note that if $\sigma$ is a finite permutation, $e_\sigma = e$. To see this, note that we may add a $\hat{\sigma}$ before the $f$ as well, by assumption.
    Now we can use the determinism of the $\hat{\sigma}$s, and the clear fact that 
    \[A \to \tensor A \to \tensor B \labelto{\hat{\sigma}} \tensor B = A \to \tensor A \to \tensor B\]

    Now let $\sigma$ instead be an injection. Then for each finite subset $F \subset J$, we can find a finite permutation of $J$, $\sigma_0$, such that $\sigma|_F = \sigma_0|_F$.
    Then on this marginal, $e_\sigma = e_{\sigma_0} = e$, hence $e_\sigma = e$ in general.

    Let $J = J_0 \sqcup J_1$ be a decomposition of $J$ into two disjoint subsets with the cardinality of $J$ (here we use $J$ infinite).
    Let $\tau_0, \tau_1: J \to J$ be injections with image $J_0,J_1$ respectively.

    Now consider the map $a_\sigma: A \to T \tensor T$ given by composing $e_\sigma$ with $t$.
    By the above, they all agree.
    By the lemma, we see that the maps $\tensor_J X \labelto{\hat{\sigma}} \tensor_J X \to T$ are all $\tensor_J p$ a.e. equal.
    Applying this to $\tau_0,\tau_1$, we get that the map $A \to T$ must be deterministic.
\end{proof}
In the last step, the idea is that precomposing with $\hat{\tau_0}$ and $\hat{\tau_1}$ is essentially picking out two disjoint subsets and using them to determine $T$.
Since all the variables are independent, these two are clearly independent, but also equal (by the preceding argument). Hence they are deterministic, but they also agree with the original map.

\section{Examples}
As noted, theorems \cref{thm:kolmog} and \cref{thm:hewsav}, when intepreted in the Markov category $\mathsf{Stoch}$, recover the classical Kolmogorov and Hewitt-Savage zero to one laws.
\improve{Maybe move those examples to here? Also figure out where to put proof that $Kl(H)$ has infinite tensor product and Kolmogorov extension. (And introduce $H$)}

By intepreting them in other Markov categories, we obtain other nontrivial (although hardly particularly deep) statements:

\begin{corollary}
    Let $\{X_i\}_{i \in J}$ be a family of topological spaces, $Y$ a Hausdorff space, and let $f: \prod_i X_i \to Y$ be a continuous function
    which is independent of any finite prefix of the input.
    Then the map $f$ is constant.
\end{corollary}
\begin{corollary}
    Let $X, Y$ be topological spaces, $Y$ Hausdorff, and let $f: \prod_{i\in J} X \to Y$ be a continuous function which is independent of any finite permutation of the input.
    Then $f$ is constant.
\end{corollary}
\begin{proof}
    The theorems follow from \cref{thm:kolmog} and \cref{thm:hewsav}, applied to the Kleisli category $Kl(H)$ of the hyperspace monad,
    using the maps $* \to X_i$ and $* \to X$ given by the closed subsets $X_i \subseteq X_i, X \subset X$.
    The conclusion is that the closure of the image, call it $A$, has the following property: $\overline{\{(a,a) \mid a \in A\}} = A \times A$ as subsets of $Y \times Y$.
    But since the diagonal is closed in $Y$, this clearly implies that $A$ must be a singleton.
\end{proof}


\section{Speculation}
\todo[inline]{not sure if this section is any good}
It would good to have a way of using this theorem without assuming that the category in question has these infinite tensor products.
We can always make sense of the notion of an infinite independent collection of random variables (just a collection of maps $I \to X_i$).
Of course to talk about an outcome or a function which depends on the outcome of all the $X_i$, we need a map $\prod_i X_i \to T$ of some type.
But since this map is deterministic, we may want to talk about it without admitting it to our category of Markov kernels.

As an example, the probability theory of finite or countable sets is much simpler than the probability theory of infinite sets, since the whole edifice of $\sigma$-algebras can be done away with.
This is a reason to prefer $\sf{FinStoch}$ over the full $\sf{Stoch}$.
In this case, it would be desirable to be able to apply this theorem, given a collection of finite variables $I \to X_i$ and a function $\prod_i X_i \to Y$
(which may be required to satisfy some condition like continuity in the product topology), without begin required to invent the larger category $\sf{Stoch}$.

For instance, maybe there is a Markov category with objects the profinite sets, which can be obtained from $\sf{FinStoch}$ by some formal construction (maybe even simply as the pro-category), which admits infinite tensor products, and where one can profitably interpret this theorem.


\bibliographystyle{plain}
\bibliography{categorical-zero-one}

\end{document}
